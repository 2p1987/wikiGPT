{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils to assess model size given its architecture\n",
    "def n_params(model_dim: int, n_heads: int, n_kv_heads: int, head_dim : int, n_layers: int, hidden_dim: int, vocab_size: int, verbose: bool = False, num_experts: int = 1) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Computes the number of parameters of a Transformer model given its architecture.\n",
    "    \"\"\"\n",
    "    hidden_dim = int(2 * 2 * hidden_dim / 3)\n",
    "    real_hidden_dim = 16 * ((hidden_dim + 16 - 1) // 16)\n",
    "    embedding_dim = model_dim * vocab_size\n",
    "    attention_qo = model_dim * n_heads * head_dim * 2 # no bias\n",
    "    attention_kv = model_dim * n_kv_heads * head_dim * 2 # no bias\n",
    "    ff = model_dim * real_hidden_dim * 3 # no bias\n",
    "    ff_moe = ff * num_experts # no bias\n",
    "    attention_norm = model_dim * 2\n",
    "    transformer_block = attention_qo + attention_kv + ff + attention_norm\n",
    "    transformer_block_moe = attention_qo + attention_kv + ff_moe + attention_norm\n",
    "    final_norm = model_dim \n",
    "    \n",
    "    total = embedding_dim + n_layers * transformer_block + final_norm \n",
    "    total_moe = embedding_dim + n_layers * transformer_block_moe + final_norm\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "        print(\"== EMBEDDING ==\")\n",
    "        print(f\"EMBEDDING DIM: {embedding_dim: ,}\")\n",
    "\n",
    "        print(\"== TRANSFORMER BLOCK ==\")\n",
    "        print(f\"ATTENTION Query / Output: {attention_qo: ,}\")\n",
    "        print(f\"ATTENTION Key / Value: {attention_kv: ,}\")\n",
    "        print(f\"FF: {ff: ,}\")\n",
    "        print(f\"FF MOE for {num_experts} experts: {ff_moe: ,}\")\n",
    "        print(f\"ATTENTION NORM: {attention_norm: ,}\")\n",
    "        print(f\"TOTAL PER TRANSFORMER BLOCK: {transformer_block: ,}\")\n",
    "\n",
    "        print(\"== FINAL NORM ==\")\n",
    "        print(f\"FINAL NORM: {final_norm: ,}\")\n",
    "\n",
    "        print(\"== TOTAL PARAMS ==\")\n",
    "        print(f\"TOTAL PARAMS: {total: ,}\")\n",
    "        print(f\"TOTAL PARAMS MOE: {total_moe: ,}\")\n",
    "    \n",
    "    return total, total_moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== EMBEDDING ==\n",
      "EMBEDDING DIM:  32,768,000\n",
      "== TRANSFORMER BLOCK ==\n",
      "ATTENTION Query / Output:  2,097,152\n",
      "ATTENTION Key / Value:  524,288\n",
      "FF:  6,291,456\n",
      "FF MOE for 12 experts:  75,497,472\n",
      "ATTENTION NORM:  2,048\n",
      "TOTAL PER TRANSFORMER BLOCK:  8,914,944\n",
      "== FINAL NORM ==\n",
      "FINAL NORM:  1,024\n",
      "== TOTAL PARAMS ==\n",
      "TOTAL PARAMS:  157,578,240\n",
      "TOTAL PARAMS MOE:  1,126,462,464\n"
     ]
    }
   ],
   "source": [
    "_ = n_params(model_dim=1024, n_heads=16, n_kv_heads=4, head_dim=64, n_layers=14, hidden_dim=1536, vocab_size=32000, num_experts=12, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flops(context_length: int, vocab_size: int, dim_model: int, n_heads: int, n_layers: int, hidden_dim: int, verbose: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Computes the number of FLOPS of a Transformer model given its architecture.\n",
    "    Following Chinchilla paper and nanoGPT implementation from A. Karpathy.\n",
    "    \"\"\"\n",
    "    key_size = dim_model // n_heads\n",
    "    hidden_dim = int(2 * 2 * hidden_dim / 3)\n",
    "    real_hidden_dim = 16 * ((hidden_dim + 16 - 1) // 16)\n",
    "\n",
    "    # embedding\n",
    "    embedding = 2 * vocab_size * dim_model * context_length # TODO: check why we have 2 operations here\n",
    "    # attention\n",
    "    ## key, query, value projections\n",
    "    attention = 2 * 3 * dim_model * key_size * context_length \n",
    "    ## key @ query logits\n",
    "    attlogits = 2 * context_length * context_length * n_heads * key_size\n",
    "    ## softmax\n",
    "    attsoftmax = 3 * n_heads * context_length * context_length\n",
    "    ## value @ attention\n",
    "    attvalue = 2 * context_length * context_length * n_heads * key_size\n",
    "    ## attention output projection\n",
    "    attout = 2 * context_length * key_size * n_heads * dim_model\n",
    "\n",
    "    att= attention + attlogits + attsoftmax + attvalue + attout\n",
    "\n",
    "    # feedforward\n",
    "    ff = 2 * context_length * dim_model * real_hidden_dim * 3 # we have 3 projections with the activation function\n",
    "\n",
    "    # logits\n",
    "    logits = 2 * context_length * vocab_size * dim_model\n",
    "\n",
    "    forward_flops = embedding + n_layers * (att + ff) + logits # NB this apparently differs from Chinchilla paper as they do not count embedding and logits\n",
    "    backward_flops = 2 * forward_flops # from Kaplan et al. 2020 paper\n",
    "\n",
    "    total_flops = forward_flops + backward_flops\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"TOTAL FLOPS: {total_flops: e}\") \n",
    "    return total_flops\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FLOPS:  1.160144e+12\n"
     ]
    }
   ],
   "source": [
    "_ = compute_flops(context_length=1024, vocab_size=8000, dim_model=2048, n_heads=16, n_layers=6, hidden_dim=2048, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimal compute budget\n",
    "\n",
    "# raw data (params, tokens) from Chinchilla paper\n",
    "raw = [\n",
    "    [400e6, 7.7e9],\n",
    "    [1e9, 20.0e9],\n",
    "    [10e9, 219.5e9],\n",
    "    [67e9, 1.7e12],\n",
    "    [175e9, 4.3e12],\n",
    "    [280e9, 7.1e12],\n",
    "    [520e9, 13.4e12],\n",
    "    [1e12, 26.5e12],\n",
    "    [10e12, 292.0e12]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1.04x + 0.94\n"
     ]
    }
   ],
   "source": [
    "# fitting a linear regression\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([np.log10(x[0]) for x in raw])\n",
    "y = np.array([np.log10(x[1]) for x in raw])\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "print(f\"y = {m:.2f}x + {c:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_tokens_for_params(params: int) -> None:\n",
    "    \"\"\"\n",
    "    Computes the optimal number of tokens given a number of parameters.\n",
    "    \"\"\"\n",
    "    print(f\"Number of optimal tokens for model params {params: e} ==> {10 ** ((np.log10(params) * m) + c): e}\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of optimal tokens for model params  2.300000e+09 ==>  4.792342e+10\n"
     ]
    }
   ],
   "source": [
    "get_optimal_tokens_for_params(2.3e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate largest possible model for a given flops budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    vocab_size = trial.suggest_categorical('vocab_size', [2000, 4000, 8000, 16000, 32000])\n",
    "    model_dim = trial.suggest_categorical('model_dim', [256, 512, 640, 768, 1024])\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 12)\n",
    "    n_heads = trial.suggest_int('n_heads', 1, 12)\n",
    "    head_dim = model_dim // n_heads\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [256, 512, 640, 768, 1024])\n",
    "\n",
    "    flops = compute_flops(context_length=256, vocab_size=vocab_size, dim_model=model_dim, n_heads=n_heads, n_layers=n_layers, hidden_dim=hidden_dim)\n",
    "\n",
    "    if abs(flops - 4.9e10) < 1e10: # this is our compute budget\n",
    "        params = n_params(model_dim=model_dim, n_heads=n_heads, head_dim=head_dim, n_layers=n_layers, hidden_dim=hidden_dim, vocab_size=vocab_size)\n",
    "    else:\n",
    "        params = 0\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name=\"max_params_for_budget\",direction='maximize')\n",
    "study.optimize(objective, n_trials=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = n_params(head_dim=1024//16, model_dim=1024, n_layers=11, n_heads=16, hidden_dim=256, vocab_size=2000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = compute_flops(context_length=256, vocab_size=2000, dim_model=1024, n_heads=16, n_layers=11, hidden_dim=256, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_optimal_tokens_for_params(0.2e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration to reach 1e9 tokens\n",
    "\n",
    "total_tokens = 1.1e9\n",
    "batch_size = 32\n",
    "context_length = 256\n",
    "\n",
    "total_tokens / (batch_size * context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
